import os
import json
# from openai import OpenAI # Example\
from google import genai
from dotenv import load_dotenv
load_dotenv(override=True)

class LLMConnector:
    def __init__(self, llm_provider="google", api_key=None, model_name=None):
        """
        Manages connection, auth, and API calls to the LLM.
        Args:
            llm_provider (str): 'openai', 'google', 'mock', etc.
            api_key (str, optional): API key. Defaults to env var.
            model_name (str, optional): Specific LLM model.
        """
        self.provider = llm_provider
        if not api_key:
            self.api_key = os.getenv("GEMINI_API_KEY")
        else:
            self.api_key =  api_key
        if model_name:
            self.model_name = model_name
        else:
            self.model_name = "gemini-2.0-flash"
    
        if llm_provider=='google':
            self.client = genai.Client(api_key=self.api_key)

    def get_llm_response(self, prompt_text: str) -> str:
        """
        Sends the prompt to the LLM and retrieves the raw response.

        Args:
            prompt_text (str): The prompt generated by PromptGenerator.

        Returns:
            str: The raw JSON string response from the LLM.
        """
        print(f"\nSending prompt to LLM ({self.provider})...")
        # print("Prompt snippet:", prompt_text[:200] + "...") # For debugging

        response = self.client.models.generate_content(
            model=self.model_name, contents=prompt_text
        )
        return response.text
            
    
# # Example Usage
# if __name__ == "__main__":
#     # connector = LLMConnector(llm_provider="openai") # or "google"
#     connector = LLMConnector(llm_provider="mock")
#     sample_prompt = "Recommend one brawler for an aggressive player. Respond in JSON: {'character_recommendations_output': {'recommendations': [{'characterName': 'X', 'reasoning': '...'}]}}"
    
#     raw_llm_output = connector.send_prompt(sample_prompt)
#     print("\nRaw LLM Output (Mock):")
#     print(raw_llm_output)
#     try:
#         parsed_output = json.loads(raw_llm_output)
#         print("\nParsed LLM Output:")
#         print(json.dumps(parsed_output, indent=2))
#     except json.JSONDecodeError:
#         print("Failed to parse LLM output as JSON.")
